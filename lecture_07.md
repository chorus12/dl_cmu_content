# lecture_07
[Reddit discussion](https://www.reddit.com/r/IntroToDL/comments/d6tv05/lecture_07_and_discussion/)

## Description:
  - Convergence in neural networks
  - Rates of convergence
  - Loss surfaces
  - Learning rates, and optimization methods
  - RMSProp, Adagrad, Momentum

## Video:
[![lecture_07](https://img.youtube.com/vi/sd7qhTKIi4Y/0.jpg)](https://www.youtube.com/watch?v=sd7qhTKIi4Y)
